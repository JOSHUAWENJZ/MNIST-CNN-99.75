{
  "cells": [
    {
      "metadata": {
        "_uuid": "4ae43cc1419d7809130b937ded044b01f169de5b"
      },
      "cell_type": "markdown",
      "source": "# MNIST Accuracy = 99.79%\nIt's amazing that convolutional neural networks can classify handwritten digits so accurately. In this notebook, we witness an ensemble of 15 CNNs classify MNIST's 10,000 test images after training on MNIST's 60,000 training images plus 25 million more images created by rotating, scaling, and shifting MNIST's training images. Learning from 25,060,000 images, this ensemble of CNNs achieves 99.79% classification accuracy (with average accuracy 99.745% and standard deviation of 0.020 as indicated by 100 trials). This accuracy revivals the best to date. This notebook uses ideas from the best published models found on the internet. Advanced techniques include data augmentation, nonlinear convolution layers, learnable pooling layers, ReLU activation, ensembling, bagging, decaying learning rates, dropout, batch normalization, and adam optimization.\n\nMore information about this ensemble of CNNs can be found [here][1].\n[1]:https://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a8411c264c011affb4288c66e435e7f5f6c85604",
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# LOAD LIBRARIES\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n# USE KERAS WITH DEFAULT TENSORFLOW BACKEND\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.datasets import mnist",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "493810e8bb77663d047c75b1844519103b9804bb"
      },
      "cell_type": "markdown",
      "source": "# Load MNIST's 60,000 training images"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# LOAD MNIST DATASET AS 60K TRAIN AND 10K TEST\n(x_train, y_train), (x_test, y_test) = mnist.load_data()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24d4db9cf6ed9d45b78b65f06ad333fc4b05f8d2",
        "collapsed": true,
        "_kg_hide-input": false
      },
      "cell_type": "code",
      "source": "# PREPARE DATA FOR NEURAL NETWORK\nX_train = x_train / 255.0\nX_test = x_test / 255.0\nX_train = X_train.reshape(-1,28,28,1)\nX_test = X_test.reshape(-1,28,28,1)\nY_train = to_categorical(y_train, num_classes = 10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5e680a97411235e02fc46a9ec1db02196beb5022"
      },
      "cell_type": "markdown",
      "source": "# Generate 25 million more images!!\nby randomly rotating, scaling, and shifting MNIST's 60,000 training images."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5f518935da8ae1b48e6e9a441b5f973f69210e63",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# CREATE MORE IMAGES WITH DATA AUGMENTATION\ndatagen = ImageDataGenerator(\n        rotation_range=15,\n        zoom_range = 0.15,  \n        width_shift_range=0.1, \n        height_shift_range=0.1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fd6c228ea771303a3e06b6ec3936e0729a632790"
      },
      "cell_type": "markdown",
      "source": "# Build 15 Convolutional Neural Networks!"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "acb0d6d03254aedbf87063d6066068e6688e094c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# BUILD CONVOLUTIONAL NEURAL NETWORKS\nnets = 15\nmodel = [0] *nets\nfor j in range(nets):\n    model[j] = Sequential()\n\n    model[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n    model[j].add(BatchNormalization())\n    model[j].add(Conv2D(32, kernel_size = 3, activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Dropout(0.4))\n\n    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Dropout(0.4))\n\n    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Flatten())\n    model[j].add(Dropout(0.4))\n    model[j].add(Dense(10, activation='softmax'))\n\n    # COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "942355bd9bf637c7c83716b99c197a02dcdddc84"
      },
      "cell_type": "markdown",
      "source": "# Train 15 CNN"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "72eb364290d4d06d9965ede3477b62057294c8b7",
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# DECREASE LEARNING RATE BY 0.95 EACH EPOCH\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n\n# TRAIN CNNs AND DISPLAY ACCURACIES\nepochs = 30\nhistory = [0] * nets\nresults = [0] * nets\nfor j in range(nets):\n    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size = 0.1)\n    history[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n      epochs = epochs, steps_per_epoch = X_train2.shape[0]//64,\n      validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=0)\n    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format\n      (j+1,epochs,history[j].history['acc'][epochs-1],history[j].history['val_acc'][epochs-1]))\n    \n    # PREDICT DIGITS FOR CNN J ON MNIST 10K TEST\n    results[j] = model[j].predict(X_test)\n    results2 = np.argmax(results[j],axis = 1)\n\n    # CALCULATE ACCURACY OF CNN J ON MNIST 10K TEST\n    c=0\n    for i in range(10000):\n        if results2[i]!=y_test[i]:\n            c +=1\n    print(\"CNN %d: Test accuracy = %f\" % (j+1,1-c/10000.))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "397f584f86ddd65814a96abc5ac7b307fb4f8431"
      },
      "cell_type": "markdown",
      "source": "# Ensemble 15 CNN and Predict"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad8897d11d9029b11e019dfbaa51fad5fc2b78e0",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# PREDICT DIGITS FOR ENSEMBLE ON MNIST 10K TEST\nresults2 = np.zeros( (X_test.shape[0],10) )\nfor j in range(nets):\n    results2 = results2 + results[j]\nresults2 = np.argmax(results2,axis = 1)\n \n# CALCULATE ACCURACY OF ENSEMBLE ON MNIST 10K TEST SET    \nc=0\nfor i in range(10000):\n    if results2[i]!=y_test[i]:\n        c +=1\nprint(\"Ensemble Accuracy = %f\" % (1-c/10000.))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "19f73abfa0fdfc8d87017c6a907ce5630cfcd380"
      },
      "cell_type": "markdown",
      "source": "# Performance\nA neural network learns different weights and biases each time you train it. Therefore this notebook was exectuted 100 times to assess performance. This ensemble's average accuracy classifying MNIST 10k test images is 99.745% with standard deviation of 0.020 and maximum accuracy 99.79%. An individual CNN's average accuracy is 99.641% with standard deviation of 0.047 and maximum accuracy 99.81%. The accuracy of this code for classifying MNIST test images rivals the best reported to date. A list of the best classifiers can be found [here][1]. More information about this ensemble of CNNs can be found [here][2].\n[1]:http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n[2]:https://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
